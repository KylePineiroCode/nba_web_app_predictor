{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Win/Loss modeling and tuning\n",
    "\n",
    "Uses the engineered team-game dataset to train and compare a strong baseline logistic model and a tree ensemble (HistGradientBoosting) with chronological validation to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f575f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, brier_score_loss, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = Path('../data/team_game_dataset.csv')\n",
    "assert DATA_PATH.exists(), 'Run the EDA notebook to produce data/team_game_dataset.csv first.'\n",
    "\n",
    "# Load and sort to keep chronology\n",
    "raw = pd.read_csv(DATA_PATH)\n",
    "raw['Data'] = pd.to_datetime(raw['Data'])\n",
    "raw = raw.sort_values('Data').reset_index(drop=True)\n",
    "\n",
    "# Target and feature split\n",
    "y = raw['win']\n",
    "X = raw.drop(columns=['win', 'Data'])\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "cat_cols = ['Tm', 'Opp']\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Train/test chronological split (last 20% for test)\n",
    "split_idx = int(len(raw) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e856cd4",
   "metadata": {},
   "source": [
    "## Preprocess and models\n",
    "- ColumnTransformer: one-hot encode team IDs, impute missing, scale numerics.\n",
    "- Logistic Regression (L2, balanced class weights).\n",
    "- HistGradientBoosting (tree ensemble good for tabular)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc8f10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "categorical = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('cat', categorical, cat_cols),\n",
    "    ('num', numeric, num_cols)\n",
    "])\n",
    "\n",
    "# Models\n",
    "log_reg = LogisticRegression(max_iter=200, class_weight='balanced')\n",
    "hgb = HistGradientBoostingClassifier(max_depth=6, learning_rate=0.08, max_iter=300)\n",
    "\n",
    "pipelines = {\n",
    "    'log_reg': Pipeline([('prep', preprocess), ('clf', log_reg)]),\n",
    "    'hgb': Pipeline([('prep', preprocess), ('clf', hgb)]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039f090",
   "metadata": {},
   "source": [
    "## Train and evaluate\n",
    "Metrics: accuracy, ROC-AUC, Brier score. Also view classification report for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef4f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model comparison (higher accuracy/roc_auc, lower brier):\n",
      "         accuracy  roc_auc         brier\n",
      "log_reg       1.0      1.0  4.873060e-03\n",
      "hgb           1.0      1.0  2.478946e-12\n",
      "Best model: log_reg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       153\n",
      "           1      1.000     1.000     1.000       154\n",
      "\n",
      "    accuracy                          1.000       307\n",
      "   macro avg      1.000     1.000     1.000       307\n",
      "weighted avg      1.000     1.000     1.000       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, pred),\n",
    "        'roc_auc': roc_auc_score(y_test, proba),\n",
    "        'brier': brier_score_loss(y_test, proba)\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T.sort_values('roc_auc', ascending=False)\n",
    "print('Model comparison (higher accuracy/roc_auc, lower brier):')\n",
    "print(results_df)\n",
    "\n",
    "best_name = results_df.index[0]\n",
    "best_pipe = pipelines[best_name]\n",
    "best_pred = (best_pipe.predict_proba(X_test)[:, 1] >= 0.5).astype(int)\n",
    "print(f\"Best model: {best_name}\")\n",
    "print(classification_report(y_test, best_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f0603",
   "metadata": {},
   "source": [
    "## Grid search (time-aware)\n",
    "\n",
    "Tune HistGradientBoosting hyperparameters with TimeSeriesSplit and select by ROC-AUC; evaluate the best on the held-out test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d441c433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Best params: {'clf__learning_rate': 0.03, 'clf__max_depth': 4, 'clf__max_iter': 200, 'clf__min_samples_leaf': 20}\n",
      "Best CV ROC-AUC: 1.0\n",
      "Test ROC-AUC: 1.0\n",
      "Test Accuracy: 1.0\n",
      "Test Brier: 1.5042070228258165e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       153\n",
      "           1      1.000     1.000     1.000       154\n",
      "\n",
      "    accuracy                          1.000       307\n",
      "   macro avg      1.000     1.000     1.000       307\n",
      "weighted avg      1.000     1.000     1.000       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4)\n",
    "param_grid_hgb = {\n",
    "    'clf__max_depth': [4, 6, 8],\n",
    "    'clf__learning_rate': [0.03, 0.05, 0.08, 0.12],\n",
    "    'clf__max_iter': [200, 300, 500],\n",
    "    'clf__min_samples_leaf': [20, 50, 100]\n",
    "}\n",
    "\n",
    "hgb_base = Pipeline([('prep', preprocess), ('clf', HistGradientBoostingClassifier())])\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=hgb_base,\n",
    "    param_grid=param_grid_hgb,\n",
    "    cv=tscv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best params:', gs.best_params_)\n",
    "print('Best CV ROC-AUC:', gs.best_score_)\n",
    "\n",
    "best_hgb = gs.best_estimator_\n",
    "proba = best_hgb.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "print('Test ROC-AUC:', roc_auc_score(y_test, proba))\n",
    "print('Test Accuracy:', accuracy_score(y_test, pred))\n",
    "print('Test Brier:', brier_score_loss(y_test, proba))\n",
    "print(classification_report(y_test, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8f186",
   "metadata": {},
   "source": [
    "##  Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35af72b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to models/win_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(best_pipe, '../models/win_classifier.joblib')\n",
    "print('Saved best model to models/win_classifier.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
